{
 "cells": [
  {
   "cell_type": "raw",
   "id": "a5cb8d08",
   "metadata": {},
   "source": [
    "1. What is the function of a summation junction of a neuron? What is threshold activation\n",
    "function?\n",
    " A function that combines the various input activations into a single activation.\n",
    "2. What is a step function? What is the difference of step function with threshold function?\n",
    "Activation functions can be categorized into three main categories:\n",
    "\n",
    "Binary Step Function\n",
    "Linear Activation Function\n",
    "Non-Linear Activation functions\n",
    "Sigmoid function\n",
    "tanh function\n",
    "ReLU function\n",
    "\n",
    "Binary step function is one of the simplest activation functions. The function produces binary output and thus the name binary step funtion. The function produces 1 (or true) when input passes a threshold limit whereas it produces 0 (or false) when input does not pass threshold.\n",
    "\n",
    "\n",
    "3. Explain the McCulloch–Pitts model of neuron.\n",
    "\n",
    "The McCulloch-Pitts neural model, which was the earliest ANN model, has only two types of inputs — Excitatory and Inhibitory. The excitatory inputs have weights of positive magnitude and the inhibitory weights have weights of negative magnitude. The inputs of the McCulloch-Pitts neuron could be either 0 or 1. It has a threshold function as an activation function. So, the output signal yout is 1 if the input ysum is greater than or equal to a given threshold value, else 0\n",
    "\n",
    "\n",
    "4. Explain the ADALINE network model.\n",
    "Adaline which stands for Adaptive Linear Neuron, is a network having a single linear unit. It was developed by Widrow and Hoff in 1960. Some important points about Adaline are as follows −\n",
    "\n",
    "It uses bipolar activation function.\n",
    "Adaline neuron can be trained using Delta rule or Least Mean Square(LMS) rule or widrow-hoff rule\n",
    "The net input is compared with the target value to compute the error signal.\n",
    "on the basis of adaptive training algoritham weights are adjusted\n",
    "\n",
    "\n",
    "5. What is the constraint of a simple perceptron? Why it may fail with a real-world data set?\n",
    "The basic example of a neural network is a ‘perceptron’. It was invented by Frank Rosenblatt in 1957. The perceptron is a classification algorithm similar to logistic regression. This because, similar to logistic regression, a perceptron has weights, w, and an output function, ‘f’, which is a dot product of the weights and the input.\n",
    "A \n",
    "\n",
    "perceptron model has limitations as follows:\n",
    "\n",
    "The output of a perceptron can only be a binary number (0 or 1) due to the hard limit transfer function.\n",
    "Perceptron can only be used to classify the linearly separable sets of input vectors. If input vectors are non-linear, it is not easy to classify them properly.\n",
    "\n",
    "\n",
    "6. What is linearly inseparable problem? What is the role of the hidden layer?\n",
    "Linear separability is a property of two sets of points. This is most easily visualized in two dimensions (the Euclidean plane) by thinking of one set of points as being colored blue and the other set of points as being colored red. These two sets are linearly separable if there exists at least one line in the plane with all of the blue points on one side of the line and all the red points on the other side.\n",
    "As we know that a single perceptron consists of inputs, weights, bias, and an activation function to serve the output.\n",
    "\n",
    "Let us assume the output of the perceptron to be y, and let x be an input to the perceptron with a single input.\n",
    "\n",
    "Then y = w1*x + b, where w1 is the weight for the input, and b is the bias.\n",
    "\n",
    "Let us further simplify this problem by assuming w1 to be 1, and b to be 0.\n",
    "\n",
    "This makes our equation to be y = x, which is the equation of the straight line passing through the origin.\n",
    "\n",
    "7. Explain XOR problem in case of a simple perceptron.\n",
    "\n",
    "8. Design a multi-layer perceptron to implement A XOR B.\n",
    "import numpy as np\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=2,activation=’relu’,input_dim=2))\n",
    "model.add(Dense(units=1,activation=’sigmoid’))\n",
    "\n",
    "model.compile(loss=’binary_crossentropy’,optimizer=’adam’,metrics=[‘accuracy’])\n",
    "\n",
    "print(model.summary())\n",
    "print(model.get_weights())\n",
    "\n",
    "x = np.array([[0.,0.],[0.,1.],[1.,0.],[1.,1.]])\n",
    "y = np.array([0.,1.,1.,0.])\n",
    "\n",
    "model.fit(x,y,epochs=1000,batch_size=4)\n",
    "\n",
    "print(model.get_weights())\n",
    "\n",
    "print(model.predict(x,batch_size=4))\n",
    "\n",
    "\n",
    "9. Explain the single-layer feed forward architecture of ANN.\n",
    "The simplest kind of neural network is a single-layer perceptron network, which consists of a single layer of output nodes; the inputs are fed directly to the outputs via a series of weights. In this way it can be considered the simplest kind of feed-forward network. The sum of the products of the weights and the inputs is calculated in each node, and if the value is above some threshold (typically 0) the neuron fires and takes the activated value (typically 1); otherwise it takes the deactivated value (typically -1). Neurons with this kind of activation function are also called artificial neurons or linear threshold units. In the literature the term perceptron often refers to networks consisting of just one of these units.\n",
    "\n",
    "\n",
    "10. Explain the competitive network architecture of ANN.\n",
    "\n",
    "\n",
    "\n",
    "11. Consider a multi-layer feed forward neural network. Enumerate and explain steps in the\n",
    "backpropagation algorithm used to train the network.\n",
    "12. What are the advantages and disadvantages of neural networks?\n",
    "13. Write short notes on any two of the following:\n",
    "\n",
    "1. Biological neuron\n",
    "2. ReLU function\n",
    "3. Single-layer feed forward ANN\n",
    "4. Gradient descent\n",
    "5. Recurrent networks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
